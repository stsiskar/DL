<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Convolution ‚Äì How It Really Works</title>

  <!-- Mobile-friendly -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- Simple styling -->
  <style>
    :root {
      --bg: #0f172a;
      --panel: #020617;
      --accent: #38bdf8;
      --accent-soft: rgba(56, 189, 248, 0.12);
      --text: #e5e7eb;
      --muted: #9ca3af;
      --border: #1f2937;
      --danger: #f97373;
      --code-bg: #020617;
      --conv: #22c55e;
      --relu: #f97316;
      --pool: #3b82f6;
      --fc: #eab308;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
        sans-serif;
      background: radial-gradient(circle at top left, #1f2937 0, #020617 55%);
      color: var(--text);
      line-height: 1.6;
    }

    .page {
      max-width: 960px;
      margin: 0 auto;
      padding: 2.5rem 1.25rem 3rem;
    }

    header {
      text-align: center;
      margin-bottom: 2.5rem;
    }

    header h1 {
      font-size: clamp(1.8rem, 3vw, 2.4rem);
      margin: 0 0 0.25rem;
    }

    header p {
      margin: 0.2rem 0;
      color: var(--muted);
      font-size: 0.95rem;
    }

    .badge {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.2rem 0.7rem;
      border-radius: 999px;
      font-size: 0.8rem;
      background: rgba(56, 189, 248, 0.16);
      color: var(--accent);
      margin-bottom: 0.7rem;
    }

    .badge span.icon {
      font-size: 1rem;
    }

    h2 {
      margin-top: 2rem;
      margin-bottom: 0.7rem;
      font-size: 1.35rem;
      border-bottom: 1px solid var(--border);
      padding-bottom: 0.3rem;
    }

    h3 {
      margin-top: 1.4rem;
      margin-bottom: 0.4rem;
      font-size: 1.1rem;
    }

    p {
      margin: 0.4rem 0;
    }

    ul {
      margin: 0.4rem 0 0.6rem 1.2rem;
    }

    code {
      font-family: "JetBrains Mono", ui-monospace, SFMono-Regular, Menlo,
        Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.9rem;
      background: var(--code-bg);
      padding: 0.05rem 0.25rem;
      border-radius: 4px;
    }

    pre code {
      display: block;
      padding: 0.8rem 1rem;
      border-radius: 0.75rem;
      border: 1px solid var(--border);
      overflow-x: auto;
    }

    .panel {
      background: rgba(15, 23, 42, 0.92);
      border-radius: 1rem;
      padding: 1.2rem 1.4rem;
      border: 1px solid var(--border);
      margin: 1rem 0 1.3rem;
    }

    .panel.soft {
      background: var(--accent-soft);
      border-color: rgba(56, 189, 248, 0.35);
    }

    .note {
      font-size: 0.9rem;
      color: var(--muted);
    }

    .equation {
      text-align: center;
      margin: 0.7rem 0;
      font-size: 1.02rem;
    }

    .equation span {
      background: rgba(15, 23, 42, 0.7);
      padding: 0.4rem 0.8rem;
      border-radius: 999px;
      border: 1px solid var(--border);
    }

    /* Architecture row */
    .arch-row {
      display: flex;
      flex-wrap: wrap;
      gap: 0.7rem;
      margin: 0.6rem 0 0.3rem;
    }

    .layer-chip {
      flex: 0 0 auto;
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
      padding: 0.35rem 0.8rem;
      border-radius: 999px;
      font-size: 0.9rem;
      font-weight: 500;
      background: rgba(15, 23, 42, 0.95);
      border: 1px solid var(--border);
      box-shadow: 0 0 0 1px rgba(15, 23, 42, 0.8);
    }

    .layer-chip .dot {
      width: 0.55rem;
      height: 0.55rem;
      border-radius: 999px;
      background: var(--muted);
    }

    .layer-chip.conv .dot {
      background: var(--conv);
    }

    .layer-chip.relu .dot {
      background: var(--relu);
    }

    .layer-chip.pool .dot {
      background: var(--pool);
    }

    .layer-chip.fc .dot {
      background: var(--fc);
    }

    .arrow {
      flex: 0 0 auto;
      display: flex;
      align-items: center;
      font-size: 1.1rem;
      color: var(--muted);
    }

    .legend {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(170px, 1fr));
      gap: 0.6rem;
      margin-top: 0.7rem;
      font-size: 0.9rem;
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 0.4rem;
      color: var(--muted);
    }

    .legend-item .swatch {
      width: 0.7rem;
      height: 0.7rem;
      border-radius: 999px;
    }

    .swatch.conv { background: var(--conv); }
    .swatch.relu { background: var(--relu); }
    .swatch.pool { background: var(--pool); }
    .swatch.fc   { background: var(--fc); }

    @media (prefers-color-scheme: light) {
      body {
        background: #f3f4f6;
        color: #0f172a;
      }
      .panel,
      .layer-chip {
        background: #ffffff;
        border-color: #e5e7eb;
      }
      .equation span {
        background: #f9fafb;
      }
      .note {
        color: #6b7280;
      }
    }
  </style>

  <!-- Optional: MathJax for LaTeX-style equations -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
      svg: { fontCache: 'global' }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
  <div class="page">
    <header>
      <div class="badge">
        <span class="icon">üß†</span>
        <span>Deep Learning ‚Äì Convolution</span>
      </div>
      <h1>Convolution ‚Äì How It Really Works</h1>
      <p>A visual & intuitive view for CNNs</p>
      <p class="note">Convolution layers, ReLU, pooling, and fully connected layers in one simple story.</p>
    </header>

    <!-- 1. What is convolution? -->
    <section>
      <h2>1. What is a Convolution Layer?</h2>

      <div class="panel">
        <p>
          A convolution layer applies a small matrix of weights (a <strong>kernel</strong> or
          <strong>filter</strong>) over local patches of the input and produces new feature maps.
        </p>
        <p>
          Instead of connecting every input pixel to every output neuron, we reuse the same kernel across
          the image and keep connections <em>local</em>.
        </p>
      </div>

      <h3>1.1. Discrete convolution formula</h3>

      <p class="note">1D version (easier to read):</p>

      <div class="equation">
        <span>
          $y[n] = \sum_{k} x[n - k] \, w[k]$
        </span>
      </div>

      <p>
        Here:
      </p>
      <ul>
        <li>$x$ ‚Äì input signal (or pixel values along a row/column)</li>
        <li>$w$ ‚Äì kernel/filter weights</li>
        <li>$y$ ‚Äì output feature</li>
      </ul>

      <p class="note">
        In 2D, the idea is the same, but we slide a 2D kernel over a 2D image and sum the elementwise products.
      </p>
    </section>

    <!-- 2. Hyperparameters -->
    <section>
      <h2>2. Convolution Hyperparameters</h2>

      <div class="panel soft">
        <p><strong>Input volume:</strong> $W_1 \times H_1 \times D_1$</p>
        <p><strong>Hyperparameters:</strong></p>
        <ul>
          <li><strong>Number of filters</strong> $K$</li>
          <li><strong>Filter size</strong> (spatial extent) $F$</li>
          <li><strong>Stride</strong> $S$</li>
          <li><strong>Zero padding</strong> $P$</li>
        </ul>
        <p><strong>Output volume:</strong> $W_2 \times H_2 \times D_2$ where:</p>

        <div class="equation">
          <span>
            $W_2 = \dfrac{W_1 - F + 2P}{S} + 1$
          </span>
        </div>
        <div class="equation">
          <span>
            $H_2 = \dfrac{H_1 - F + 2P}{S} + 1$
          </span>
        </div>
        <div class="equation">
          <span>
            $D_2 = K$
          </span>
        </div>

        <p>
          With <strong>parameter sharing</strong>, each filter has $F \cdot F \cdot D_1$ weights and one bias, for a total of
          $(F \cdot F \cdot D_1) \cdot K$ weights and $K$ biases.
        </p>
      </div>
    </section>

    <!-- 3. Architecture icons -->
    <section>
      <h2>3. CNN Architecture ‚Äì Layer Icons</h2>

      <p class="note">
        A typical convolutional network alternates between convolution, nonlinearity, and downsampling, ending with
        fully connected layers.
      </p>

      <h3>3.1. Icon-style architecture row</h3>

      <div class="panel">
        <div class="arch-row">
          <div class="layer-chip conv">
            <span class="dot"></span>
            <span>Conv ‚äó</span>
          </div>
          <div class="arrow">‚á¢</div>
          <div class="layer-chip relu">
            <span class="dot"></span>
            <span>ReLU ‚Üó</span>
          </div>
          <div class="arrow">‚á¢</div>
          <div class="layer-chip pool">
            <span class="dot"></span>
            <span>Pool ‚Üì</span>
          </div>
          <div class="arrow">‚á¢</div>
          <div class="layer-chip fc">
            <span class="dot"></span>
            <span>FC ‚óè</span>
          </div>
        </div>

        <div class="legend">
          <div class="legend-item">
            <span class="swatch conv"></span>
            <span><strong>Conv</strong> ‚Äì localized, shared-weight filters (feature extraction)</span>
          </div>
          <div class="legend-item">
            <span class="swatch relu"></span>
            <span><strong>ReLU</strong> ‚Äì nonlinearity: $f(x) = \max(0, x)$</span>
          </div>
          <div class="legend-item">
            <span class="swatch pool"></span>
            <span><strong>Pool</strong> ‚Äì downsampling (max/avg), reduces spatial size</span>
          </div>
          <div class="legend-item">
            <span class="swatch fc"></span>
            <span><strong>FC</strong> ‚Äì fully connected layer for final classification</span>
          </div>
        </div>
      </div>

      <h3>3.2. Text-only variant (for slides / notes)</h3>

      <pre><code>[ Conv ] ‚Üí [ ReLU ] ‚Üí [ Pool ] ‚Üí [ FC ]</code></pre>

      <p class="note">
        Symbolic shorthand:
        <code>‚äó ‚Üí œÉ‚Å∫ ‚Üí ‚Üì ‚Üí ‚óè</code>
      </p>
    </section>

    <!-- 4. Intuition summary -->
    <section>
      <h2>4. Intuition Summary</h2>
      <ul>
        <li><strong>Convolution</strong>: learns small local patterns and reuses them everywhere in the image.</li>
        <li><strong>ReLU</strong>: keeps positive evidence, zeroes out negative values.</li>
        <li><strong>Pooling</strong>: keeps the strongest signal and makes features more invariant.</li>
        <li><strong>Fully connected</strong>: mixes high-level features to produce final scores / probabilities.</li>
      </ul>
    </section>

    <footer class="note" style="margin-top: 2rem; text-align: center; font-size: 0.85rem;">
      Built for teaching: convolution, ReLU, pooling, and fully connected layers in one page.
    </footer>
  </div>
</body>
</html>
